{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell-Export fÃ¼r Node-RED\n",
    "\n",
    "Dieses Notebook exportiert trainierte Modelle in Formate, die vom **ML Inference Node** unterstÃ¼tzt werden:\n",
    "\n",
    "1. **ONNX** - FÃ¼r sklearn/XGBoost Modelle\n",
    "2. **TensorFlow.js** - FÃ¼r Keras/TensorFlow Modelle\n",
    "3. **TensorFlow SavedModel** - Alternative fÃ¼r TensorFlow\n",
    "4. **Metadata** - JSON-Konfiguration fÃ¼r den Node\n",
    "\n",
    "## UnterstÃ¼tzte Formate im ML Inference Node\n",
    "\n",
    "| Format | Endung | Bibliothek |\n",
    "|--------|--------|------------|\n",
    "| TensorFlow.js | `model.json` | @tensorflow/tfjs-node |\n",
    "| ONNX | `.onnx` | onnxruntime-node |\n",
    "| TensorFlow SavedModel | `saved_model.pb` | @tensorflow/tfjs-node |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.056665Z",
     "iopub.status.busy": "2026-01-18T16:20:07.056422Z",
     "iopub.status.idle": "2026-01-18T16:20:07.060710Z",
     "shell.execute_reply": "2026-01-18T16:20:07.059632Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installation\n",
    "# !pip install numpy pandas scikit-learn tensorflow onnx skl2onnx tf2onnx tensorflowjs joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.062685Z",
     "iopub.status.busy": "2026-01-18T16:20:07.062461Z",
     "iopub.status.idle": "2026-01-18T16:20:07.465314Z",
     "shell.execute_reply": "2026-01-18T16:20:07.464093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup abgeschlossen!\n",
      "\n",
      "Vorhandene Modelle in ../models/trained:\n",
      "  - mlp_classifier_tfjs\n",
      "  - scaler.joblib\n",
      "  - rul_cnn_lstm.keras\n",
      "  - classification_confusion_matrices.png\n",
      "  - xgboost_classifier.joblib\n",
      "  - classification_scaler.joblib\n",
      "  - classification_metadata.json\n",
      "  - cnn_classifier.keras\n",
      "  - random_forest_classifier.joblib\n",
      "  - rul_lstm.keras\n",
      "  - rul_scaler.joblib\n",
      "  - rf_feature_importance.png\n",
      "  - autoencoder.keras\n",
      "  - pca_anomaly.joblib\n",
      "  - one_class_svm.joblib\n",
      "  - classification_data_overview.png\n",
      "  - isolation_forest.joblib\n",
      "  - autoencoder_tfjs\n",
      "  - mlp_classifier.keras\n",
      "  - rul_metadata.json\n",
      "  - rul_data_overview.png\n",
      "  - metadata.json\n",
      "  - rul_gradient_boosting.joblib\n",
      "  - model_comparison_roc.png\n",
      "  - rul_model_comparison.png\n",
      "  - isolation_forest_evaluation.png\n",
      "  - gb_feature_importance.png\n",
      "  - cnn_classifier_tfjs\n",
      "  - autoencoder_training.png\n",
      "  - lstm_training.png\n",
      "  - rul_cnn_lstm_tfjs\n",
      "  - rul_lstm_tfjs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Verzeichnisse\n",
    "TRAINED_DIR = '../models/trained'\n",
    "EXPORT_DIR = '../models/exported'\n",
    "\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup abgeschlossen!\")\n",
    "print(f\"\\nVorhandene Modelle in {TRAINED_DIR}:\")\n",
    "if os.path.exists(TRAINED_DIR):\n",
    "    for f in os.listdir(TRAINED_DIR):\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(\"  Keine Modelle gefunden. Bitte zuerst die anderen Notebooks ausfÃ¼hren.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ONNX Export fÃ¼r sklearn Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.509547Z",
     "iopub.status.busy": "2026-01-18T16:20:07.509187Z",
     "iopub.status.idle": "2026-01-18T16:20:07.534234Z",
     "shell.execute_reply": "2026-01-18T16:20:07.532672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  skl2onnx nicht installiert. ONNX-Export nicht verfÃ¼gbar.\n",
      "  Installiere mit: pip install skl2onnx onnx\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "try:\n",
    "    from skl2onnx import convert_sklearn, to_onnx\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "    import onnx\n",
    "    HAS_ONNX = True\n",
    "    print(\"ONNX-Export verfÃ¼gbar\")\n",
    "except ImportError:\n",
    "    HAS_ONNX = False\n",
    "    print(\"âš  skl2onnx nicht installiert. ONNX-Export nicht verfÃ¼gbar.\")\n",
    "    print(\"  Installiere mit: pip install skl2onnx onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.536597Z",
     "iopub.status.busy": "2026-01-18T16:20:07.536296Z",
     "iopub.status.idle": "2026-01-18T16:20:07.542127Z",
     "shell.execute_reply": "2026-01-18T16:20:07.540504Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_sklearn_to_onnx(model_path, output_path, n_features, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Exportiert ein sklearn Modell nach ONNX.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_path : str\n",
    "        Pfad zum .joblib Modell\n",
    "    output_path : str\n",
    "        Ausgabepfad fÃ¼r .onnx\n",
    "    n_features : int\n",
    "        Anzahl der Input-Features\n",
    "    model_name : str\n",
    "        Name des Modells (fÃ¼r Dokumentation)\n",
    "    \"\"\"\n",
    "    if not HAS_ONNX:\n",
    "        print(f\"âš  Ãœberspringe {model_name} (ONNX nicht verfÃ¼gbar)\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Modell laden\n",
    "        model = joblib.load(model_path)\n",
    "        \n",
    "        # Input-Typ definieren\n",
    "        initial_type = [('input', FloatTensorType([None, n_features]))]\n",
    "        \n",
    "        # Konvertieren\n",
    "        onnx_model = convert_sklearn(model, initial_types=initial_type, target_opset=12)\n",
    "        \n",
    "        # Speichern\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        \n",
    "        print(f\"âœ“ {model_name} -> {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {model_name}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.545843Z",
     "iopub.status.busy": "2026-01-18T16:20:07.545619Z",
     "iopub.status.idle": "2026-01-18T16:20:07.551079Z",
     "shell.execute_reply": "2026-01-18T16:20:07.549640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Anomalie-Erkennung ===\n",
      "âš  Ãœberspringe Isolation Forest (ONNX nicht verfÃ¼gbar)\n"
     ]
    }
   ],
   "source": [
    "# Anomalie-Erkennung Modelle exportieren\n",
    "print(\"=== Anomalie-Erkennung ===\")\n",
    "\n",
    "# Metadata laden fÃ¼r Feature-Anzahl\n",
    "try:\n",
    "    with open(f'{TRAINED_DIR}/metadata.json', 'r') as f:\n",
    "        anomaly_meta = json.load(f)\n",
    "    n_features_anomaly = anomaly_meta['n_features']\n",
    "except FileNotFoundError:\n",
    "    n_features_anomaly = 10  # Fallback\n",
    "\n",
    "# Isolation Forest\n",
    "if os.path.exists(f'{TRAINED_DIR}/isolation_forest.joblib'):\n",
    "    export_sklearn_to_onnx(\n",
    "        f'{TRAINED_DIR}/isolation_forest.joblib',\n",
    "        f'{EXPORT_DIR}/isolation_forest.onnx',\n",
    "        n_features_anomaly,\n",
    "        'Isolation Forest'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.553329Z",
     "iopub.status.busy": "2026-01-18T16:20:07.553125Z",
     "iopub.status.idle": "2026-01-18T16:20:07.559694Z",
     "shell.execute_reply": "2026-01-18T16:20:07.558099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Klassifikation ===\n",
      "âš  Ãœberspringe Random Forest Classifier (ONNX nicht verfÃ¼gbar)\n"
     ]
    }
   ],
   "source": [
    "# Klassifikation Modelle exportieren\n",
    "print(\"\\n=== Klassifikation ===\")\n",
    "\n",
    "try:\n",
    "    with open(f'{TRAINED_DIR}/classification_metadata.json', 'r') as f:\n",
    "        class_meta = json.load(f)\n",
    "    n_features_class = class_meta['n_features']\n",
    "except FileNotFoundError:\n",
    "    n_features_class = 10\n",
    "\n",
    "# Random Forest Classifier\n",
    "if os.path.exists(f'{TRAINED_DIR}/random_forest_classifier.joblib'):\n",
    "    export_sklearn_to_onnx(\n",
    "        f'{TRAINED_DIR}/random_forest_classifier.joblib',\n",
    "        f'{EXPORT_DIR}/random_forest_classifier.onnx',\n",
    "        n_features_class,\n",
    "        'Random Forest Classifier'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.561507Z",
     "iopub.status.busy": "2026-01-18T16:20:07.561292Z",
     "iopub.status.idle": "2026-01-18T16:20:07.566608Z",
     "shell.execute_reply": "2026-01-18T16:20:07.565122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUL Prediction ===\n",
      "âš  Ãœberspringe Gradient Boosting RUL (ONNX nicht verfÃ¼gbar)\n"
     ]
    }
   ],
   "source": [
    "# RUL Modelle exportieren\n",
    "print(\"\\n=== RUL Prediction ===\")\n",
    "\n",
    "try:\n",
    "    with open(f'{TRAINED_DIR}/rul_metadata.json', 'r') as f:\n",
    "        rul_meta = json.load(f)\n",
    "    n_features_rul = rul_meta['n_features']\n",
    "except FileNotFoundError:\n",
    "    n_features_rul = 10\n",
    "\n",
    "# Gradient Boosting RUL\n",
    "if os.path.exists(f'{TRAINED_DIR}/rul_gradient_boosting.joblib'):\n",
    "    export_sklearn_to_onnx(\n",
    "        f'{TRAINED_DIR}/rul_gradient_boosting.joblib',\n",
    "        f'{EXPORT_DIR}/rul_gradient_boosting.onnx',\n",
    "        n_features_rul,\n",
    "        'Gradient Boosting RUL'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow.js Export fÃ¼r Keras Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:07.569465Z",
     "iopub.status.busy": "2026-01-18T16:20:07.569163Z",
     "iopub.status.idle": "2026-01-18T16:20:12.368334Z",
     "shell.execute_reply": "2026-01-18T16:20:12.366659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 17:20:07.913068: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-18 17:20:07.920117: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-18 17:20:07.936538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768753207.962937   84395 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768753207.970464   84395 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768753207.995734   84395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768753207.995765   84395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768753207.995767   84395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768753207.995769   84395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-18 17:20:08.003781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">ðŸŒ² Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow.js Export verfÃ¼gbar (TF 2.19.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/la/private/node-red-contrib-condition-monitoring/notebooks_venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    import tensorflowjs as tfjs\n",
    "    HAS_TFJS = True\n",
    "    print(f\"TensorFlow.js Export verfÃ¼gbar (TF {tf.__version__})\")\n",
    "except ImportError:\n",
    "    HAS_TFJS = False\n",
    "    print(\"âš  tensorflowjs nicht installiert.\")\n",
    "    print(\"  Installiere mit: pip install tensorflowjs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:12.370734Z",
     "iopub.status.busy": "2026-01-18T16:20:12.370258Z",
     "iopub.status.idle": "2026-01-18T16:20:12.376137Z",
     "shell.execute_reply": "2026-01-18T16:20:12.374796Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_keras_to_tfjs(model_path, output_dir, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Exportiert ein Keras Modell nach TensorFlow.js.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_path : str\n",
    "        Pfad zum .keras Modell\n",
    "    output_dir : str\n",
    "        Ausgabeverzeichnis fÃ¼r TF.js Modell\n",
    "    model_name : str\n",
    "        Name des Modells\n",
    "    \"\"\"\n",
    "    if not HAS_TFJS:\n",
    "        print(f\"âš  Ãœberspringe {model_name} (TF.js nicht verfÃ¼gbar)\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Modell laden\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        # Zu TensorFlow.js konvertieren\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        tfjs.converters.save_keras_model(model, output_dir)\n",
    "        \n",
    "        print(f\"âœ“ {model_name} -> {output_dir}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {model_name}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:12.378218Z",
     "iopub.status.busy": "2026-01-18T16:20:12.378026Z",
     "iopub.status.idle": "2026-01-18T16:20:13.396189Z",
     "shell.execute_reply": "2026-01-18T16:20:13.394864Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 17:20:12.386622: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TensorFlow.js Export ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "âœ“ Autoencoder -> ../models/exported/autoencoder_tfjs\n",
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "âœ“ MLP Classifier -> ../models/exported/mlp_classifier_tfjs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "âœ“ 1D-CNN Classifier -> ../models/exported/cnn_classifier_tfjs\n",
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "âœ“ LSTM RUL -> ../models/exported/rul_lstm_tfjs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "âœ“ CNN-LSTM RUL -> ../models/exported/rul_cnn_lstm_tfjs\n"
     ]
    }
   ],
   "source": [
    "# Keras Modelle exportieren\n",
    "print(\"=== TensorFlow.js Export ===\")\n",
    "\n",
    "keras_models = [\n",
    "    ('autoencoder.keras', 'autoencoder_tfjs', 'Autoencoder'),\n",
    "    ('mlp_classifier.keras', 'mlp_classifier_tfjs', 'MLP Classifier'),\n",
    "    ('cnn_classifier.keras', 'cnn_classifier_tfjs', '1D-CNN Classifier'),\n",
    "    ('rul_lstm.keras', 'rul_lstm_tfjs', 'LSTM RUL'),\n",
    "    ('rul_cnn_lstm.keras', 'rul_cnn_lstm_tfjs', 'CNN-LSTM RUL'),\n",
    "]\n",
    "\n",
    "for model_file, output_name, model_name in keras_models:\n",
    "    model_path = f'{TRAINED_DIR}/{model_file}'\n",
    "    if os.path.exists(model_path):\n",
    "        export_keras_to_tfjs(\n",
    "            model_path,\n",
    "            f'{EXPORT_DIR}/{output_name}',\n",
    "            model_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras zu ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.398477Z",
     "iopub.status.busy": "2026-01-18T16:20:13.398151Z",
     "iopub.status.idle": "2026-01-18T16:20:13.403931Z",
     "shell.execute_reply": "2026-01-18T16:20:13.402448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  tf2onnx nicht installiert.\n",
      "  Installiere mit: pip install tf2onnx\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tf2onnx\n",
    "    HAS_TF2ONNX = True\n",
    "    print(\"tf2onnx verfÃ¼gbar\")\n",
    "except ImportError:\n",
    "    HAS_TF2ONNX = False\n",
    "    print(\"âš  tf2onnx nicht installiert.\")\n",
    "    print(\"  Installiere mit: pip install tf2onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.407134Z",
     "iopub.status.busy": "2026-01-18T16:20:13.406861Z",
     "iopub.status.idle": "2026-01-18T16:20:13.413099Z",
     "shell.execute_reply": "2026-01-18T16:20:13.411205Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_keras_to_onnx(model_path, output_path, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Exportiert ein Keras Modell nach ONNX.\n",
    "    \"\"\"\n",
    "    if not HAS_TF2ONNX:\n",
    "        print(f\"âš  Ãœberspringe {model_name} (tf2onnx nicht verfÃ¼gbar)\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        \n",
    "        # Modell laden\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        # Input-Signatur erstellen\n",
    "        input_signature = [tf.TensorSpec(model.input_shape, tf.float32, name='input')]\n",
    "        \n",
    "        # Konvertieren\n",
    "        onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "        \n",
    "        # Speichern\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        \n",
    "        print(f\"âœ“ {model_name} -> {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {model_name}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.415200Z",
     "iopub.status.busy": "2026-01-18T16:20:13.414969Z",
     "iopub.status.idle": "2026-01-18T16:20:13.420752Z",
     "shell.execute_reply": "2026-01-18T16:20:13.418894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Keras zu ONNX ===\n",
      "âš  Ãœberspringe Autoencoder (tf2onnx nicht verfÃ¼gbar)\n",
      "âš  Ãœberspringe MLP Classifier (tf2onnx nicht verfÃ¼gbar)\n"
     ]
    }
   ],
   "source": [
    "# Keras zu ONNX\n",
    "print(\"=== Keras zu ONNX ===\")\n",
    "\n",
    "keras_to_onnx = [\n",
    "    ('autoencoder.keras', 'autoencoder.onnx', 'Autoencoder'),\n",
    "    ('mlp_classifier.keras', 'mlp_classifier.onnx', 'MLP Classifier'),\n",
    "]\n",
    "\n",
    "for model_file, output_file, model_name in keras_to_onnx:\n",
    "    model_path = f'{TRAINED_DIR}/{model_file}'\n",
    "    if os.path.exists(model_path):\n",
    "        export_keras_to_onnx(\n",
    "            model_path,\n",
    "            f'{EXPORT_DIR}/{output_file}',\n",
    "            model_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Metadata fÃ¼r Node-RED erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.423429Z",
     "iopub.status.busy": "2026-01-18T16:20:13.423022Z",
     "iopub.status.idle": "2026-01-18T16:20:13.428892Z",
     "shell.execute_reply": "2026-01-18T16:20:13.427420Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_metadata(model_name, model_type, input_shape, output_shape, \n",
    "                          feature_names=None, class_names=None, \n",
    "                          scaler_mean=None, scaler_scale=None,\n",
    "                          description=\"\"):\n",
    "    \"\"\"\n",
    "    Erstellt Metadata-JSON fÃ¼r Node-RED ML Inference Node.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"name\": model_name,\n",
    "        \"type\": model_type,\n",
    "        \"description\": description,\n",
    "        \"input\": {\n",
    "            \"shape\": input_shape,\n",
    "            \"dtype\": \"float32\"\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"shape\": output_shape,\n",
    "            \"dtype\": \"float32\"\n",
    "        },\n",
    "        \"preprocessing\": {\n",
    "            \"normalize\": scaler_mean is not None,\n",
    "            \"mean\": scaler_mean,\n",
    "            \"scale\": scaler_scale\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if feature_names:\n",
    "        metadata[\"input\"][\"feature_names\"] = feature_names\n",
    "    \n",
    "    if class_names:\n",
    "        metadata[\"output\"][\"class_names\"] = class_names\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.430777Z",
     "iopub.status.busy": "2026-01-18T16:20:13.430592Z",
     "iopub.status.idle": "2026-01-18T16:20:13.436973Z",
     "shell.execute_reply": "2026-01-18T16:20:13.435350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metadata erstellen ===\n",
      "  Loaded: metadata.json\n",
      "  Loaded: classification_metadata.json\n",
      "  Loaded: rul_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Metadata fÃ¼r exportierte Modelle erstellen\n",
    "print(\"=== Metadata erstellen ===\")\n",
    "\n",
    "# Lade gespeicherte Metadata\n",
    "metadata_files = {\n",
    "    'anomaly': 'metadata.json',\n",
    "    'classification': 'classification_metadata.json',\n",
    "    'rul': 'rul_metadata.json'\n",
    "}\n",
    "\n",
    "loaded_metadata = {}\n",
    "for key, filename in metadata_files.items():\n",
    "    filepath = f'{TRAINED_DIR}/{filename}'\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            loaded_metadata[key] = json.load(f)\n",
    "            print(f\"  Loaded: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.439245Z",
     "iopub.status.busy": "2026-01-18T16:20:13.438968Z",
     "iopub.status.idle": "2026-01-18T16:20:13.444676Z",
     "shell.execute_reply": "2026-01-18T16:20:13.443259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ isolation_forest_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest Metadata\n",
    "if 'anomaly' in loaded_metadata:\n",
    "    meta = loaded_metadata['anomaly']\n",
    "    iso_meta = create_model_metadata(\n",
    "        model_name=\"Isolation Forest Anomaly Detector\",\n",
    "        model_type=\"anomaly_detection\",\n",
    "        input_shape=[None, meta['n_features']],\n",
    "        output_shape=[None, 1],\n",
    "        feature_names=meta.get('feature_names'),\n",
    "        scaler_mean=meta.get('scaler_mean'),\n",
    "        scaler_scale=meta.get('scaler_scale'),\n",
    "        description=\"Isolation Forest fÃ¼r Anomalie-Erkennung in Sensordaten\"\n",
    "    )\n",
    "    \n",
    "    with open(f'{EXPORT_DIR}/isolation_forest_metadata.json', 'w') as f:\n",
    "        json.dump(iso_meta, f, indent=2)\n",
    "    print(\"âœ“ isolation_forest_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.446927Z",
     "iopub.status.busy": "2026-01-18T16:20:13.446699Z",
     "iopub.status.idle": "2026-01-18T16:20:13.452453Z",
     "shell.execute_reply": "2026-01-18T16:20:13.451111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ random_forest_classifier_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Metadata\n",
    "if 'classification' in loaded_metadata:\n",
    "    meta = loaded_metadata['classification']\n",
    "    rf_meta = create_model_metadata(\n",
    "        model_name=\"Random Forest Fault Classifier\",\n",
    "        model_type=\"classification\",\n",
    "        input_shape=[None, meta['n_features']],\n",
    "        output_shape=[None, meta['n_classes']],\n",
    "        feature_names=meta.get('feature_names'),\n",
    "        class_names=meta.get('class_names'),\n",
    "        scaler_mean=meta.get('scaler_mean'),\n",
    "        scaler_scale=meta.get('scaler_scale'),\n",
    "        description=\"Random Forest zur Klassifikation von MaschinenzustÃ¤nden\"\n",
    "    )\n",
    "    \n",
    "    with open(f'{EXPORT_DIR}/random_forest_classifier_metadata.json', 'w') as f:\n",
    "        json.dump(rf_meta, f, indent=2)\n",
    "    print(\"âœ“ random_forest_classifier_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.454464Z",
     "iopub.status.busy": "2026-01-18T16:20:13.454261Z",
     "iopub.status.idle": "2026-01-18T16:20:13.460893Z",
     "shell.execute_reply": "2026-01-18T16:20:13.459365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ rul_lstm_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# LSTM RUL Metadata\n",
    "if 'rul' in loaded_metadata:\n",
    "    meta = loaded_metadata['rul']\n",
    "    lstm_meta = create_model_metadata(\n",
    "        model_name=\"LSTM RUL Predictor\",\n",
    "        model_type=\"regression\",\n",
    "        input_shape=[None, meta['sequence_length'], meta['n_features']],\n",
    "        output_shape=[None, 1],\n",
    "        feature_names=meta.get('feature_names'),\n",
    "        scaler_mean=meta.get('scaler_mean'),\n",
    "        scaler_scale=meta.get('scaler_scale'),\n",
    "        description=\"LSTM zur Vorhersage der Restlebensdauer (RUL)\"\n",
    "    )\n",
    "    lstm_meta['sequence_length'] = meta['sequence_length']\n",
    "    lstm_meta['rul_cap'] = meta['rul_cap']\n",
    "    \n",
    "    with open(f'{EXPORT_DIR}/rul_lstm_metadata.json', 'w') as f:\n",
    "        json.dump(lstm_meta, f, indent=2)\n",
    "    print(\"âœ“ rul_lstm_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verwendung in Node-RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.463009Z",
     "iopub.status.busy": "2026-01-18T16:20:13.462823Z",
     "iopub.status.idle": "2026-01-18T16:20:13.468708Z",
     "shell.execute_reply": "2026-01-18T16:20:13.467411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ README.md erstellt\n"
     ]
    }
   ],
   "source": [
    "# Anleitung fÃ¼r Node-RED generieren\n",
    "readme_content = \"\"\"\n",
    "# Exportierte Modelle fÃ¼r Node-RED\n",
    "\n",
    "Diese Modelle kÃ¶nnen mit dem **ML Inference Node** in Node-RED verwendet werden.\n",
    "\n",
    "## VerfÃ¼gbare Modelle\n",
    "\n",
    "### 1. Anomalie-Erkennung\n",
    "\n",
    "**Isolation Forest** (ONNX)\n",
    "- Datei: `isolation_forest.onnx`\n",
    "- Metadata: `isolation_forest_metadata.json`\n",
    "- Input: Array von Features (normalisiert)\n",
    "- Output: Anomalie-Score (-1 = Anomalie, 1 = Normal)\n",
    "\n",
    "```javascript\n",
    "// Beispiel: Input fÃ¼r ML Inference Node\n",
    "msg.payload = [0.5, 1.2, 0.8, 3.1, ...]; // Features\n",
    "```\n",
    "\n",
    "**Autoencoder** (TensorFlow.js)\n",
    "- Verzeichnis: `autoencoder_tfjs/`\n",
    "- Input: Array von Features (normalisiert)\n",
    "- Output: Rekonstruktion (vergleiche mit Input fÃ¼r Anomalie-Score)\n",
    "\n",
    "### 2. Fehlerklassifikation\n",
    "\n",
    "**Random Forest Classifier** (ONNX)\n",
    "- Datei: `random_forest_classifier.onnx`\n",
    "- Klassen: normal, unbalance, bearing, misalignment\n",
    "- Output: Wahrscheinlichkeiten pro Klasse\n",
    "\n",
    "**MLP Classifier** (TensorFlow.js)\n",
    "- Verzeichnis: `mlp_classifier_tfjs/`\n",
    "- Klassen: normal, unbalance, bearing, misalignment\n",
    "\n",
    "### 3. RUL Prediction\n",
    "\n",
    "**Gradient Boosting** (ONNX)\n",
    "- Datei: `rul_gradient_boosting.onnx`\n",
    "- Input: Einzelnes Feature-Array\n",
    "- Output: RUL in Zyklen (0-125)\n",
    "\n",
    "**LSTM** (TensorFlow.js)\n",
    "- Verzeichnis: `rul_lstm_tfjs/`\n",
    "- Input: Sequenz von 30 Zeitschritten\n",
    "- Output: RUL in Zyklen\n",
    "\n",
    "## Node-RED Konfiguration\n",
    "\n",
    "### ML Inference Node\n",
    "\n",
    "1. **Model Path**: Pfad zum Modell (`.onnx` oder `model.json`)\n",
    "2. **Model Type**: `onnx` oder `tensorflow`\n",
    "3. **Input Property**: `msg.payload`\n",
    "4. **Output Property**: `msg.prediction`\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Die Modelle erwarten normalisierte Eingaben. Verwende die Scaler-Parameter:\n",
    "\n",
    "```javascript\n",
    "// In einer Function Node vor ML Inference\n",
    "const mean = [...]; // Aus metadata.json\n",
    "const scale = [...]; // Aus metadata.json\n",
    "\n",
    "msg.payload = msg.payload.map((val, i) => (val - mean[i]) / scale[i]);\n",
    "return msg;\n",
    "```\n",
    "\n",
    "### Beispiel Flow\n",
    "\n",
    "```\n",
    "[Sensor Input] -> [Feature Extraction] -> [Normalize] -> [ML Inference] -> [Postprocess] -> [Output]\n",
    "```\n",
    "\n",
    "## Dateien\n",
    "\n",
    "| Datei | Format | Verwendung |\n",
    "|-------|--------|------------|\n",
    "| `*.onnx` | ONNX | ML Inference mit onnxruntime |\n",
    "| `*_tfjs/model.json` | TensorFlow.js | ML Inference mit @tensorflow/tfjs |\n",
    "| `*_metadata.json` | JSON | Preprocessing & Konfiguration |\n",
    "\"\"\"\n",
    "\n",
    "with open(f'{EXPORT_DIR}/README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"âœ“ README.md erstellt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export-Zusammenfassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.471069Z",
     "iopub.status.busy": "2026-01-18T16:20:13.470811Z",
     "iopub.status.idle": "2026-01-18T16:20:13.478622Z",
     "shell.execute_reply": "2026-01-18T16:20:13.477199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT ZUSAMMENFASSUNG\n",
      "============================================================\n",
      "\n",
      "Export-Verzeichnis: /home/la/private/node-red-contrib-condition-monitoring/models/exported\n",
      "\n",
      "Exportierte Dateien:\n",
      "  rul_lstm_metadata.json (1.5 KB)\n",
      "  README.md (2.2 KB)\n",
      "  isolation_forest_metadata.json (1.5 KB)\n",
      "  random_forest_classifier_metadata.json (1.5 KB)\n",
      "  mlp_classifier_tfjs/ (22.5 KB)\n",
      "  autoencoder_tfjs/ (22.4 KB)\n",
      "  cnn_classifier_tfjs/ (184.5 KB)\n",
      "  rul_cnn_lstm_tfjs/ (78.7 KB)\n",
      "  rul_lstm_tfjs/ (141.3 KB)\n",
      "\n",
      "GesamtgrÃ¶ÃŸe: 0.45 MB\n"
     ]
    }
   ],
   "source": [
    "# Ãœbersicht der exportierten Dateien\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPORT ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nExport-Verzeichnis: {os.path.abspath(EXPORT_DIR)}\")\n",
    "print(\"\\nExportierte Dateien:\")\n",
    "\n",
    "total_size = 0\n",
    "for root, dirs, files in os.walk(EXPORT_DIR):\n",
    "    level = root.replace(EXPORT_DIR, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    \n",
    "    if root == EXPORT_DIR:\n",
    "        for f in files:\n",
    "            filepath = os.path.join(root, f)\n",
    "            size = os.path.getsize(filepath) / 1024  # KB\n",
    "            total_size += size\n",
    "            print(f\"  {f} ({size:.1f} KB)\")\n",
    "    \n",
    "    for d in dirs:\n",
    "        dirpath = os.path.join(root, d)\n",
    "        dir_size = sum(os.path.getsize(os.path.join(dirpath, f)) for f in os.listdir(dirpath) if os.path.isfile(os.path.join(dirpath, f))) / 1024\n",
    "        total_size += dir_size\n",
    "        print(f\"  {d}/ ({dir_size:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nGesamtgrÃ¶ÃŸe: {total_size/1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:20:13.481298Z",
     "iopub.status.busy": "2026-01-18T16:20:13.481103Z",
     "iopub.status.idle": "2026-01-18T16:20:13.486256Z",
     "shell.execute_reply": "2026-01-18T16:20:13.484571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validierung: ONNX Modelle testen\n",
    "if HAS_ONNX:\n",
    "    import onnx\n",
    "    \n",
    "    print(\"\\n=== ONNX Validierung ===\")\n",
    "    \n",
    "    for f in os.listdir(EXPORT_DIR):\n",
    "        if f.endswith('.onnx'):\n",
    "            try:\n",
    "                model = onnx.load(f'{EXPORT_DIR}/{f}')\n",
    "                onnx.checker.check_model(model)\n",
    "                print(f\"âœ“ {f} - Valid\")\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— {f} - {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "### Exportierte Formate\n",
    "\n",
    "| Modell | ONNX | TensorFlow.js | Empfehlung |\n",
    "|--------|------|---------------|------------|\n",
    "| Isolation Forest | âœ“ | - | ONNX |\n",
    "| Random Forest | âœ“ | - | ONNX |\n",
    "| Gradient Boosting | âœ“ | - | ONNX |\n",
    "| Autoencoder | âœ“ | âœ“ | TF.js |\n",
    "| MLP | âœ“ | âœ“ | TF.js |\n",
    "| LSTM | - | âœ“ | TF.js |\n",
    "| CNN-LSTM | - | âœ“ | TF.js |\n",
    "\n",
    "### NÃ¤chste Schritte\n",
    "\n",
    "1. Kopiere die exportierten Modelle in das Node-RED Verzeichnis\n",
    "2. Konfiguriere den ML Inference Node mit dem Modellpfad\n",
    "3. Implementiere Preprocessing (Normalisierung) falls nÃ¶tig\n",
    "4. Teste mit echten Sensordaten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
