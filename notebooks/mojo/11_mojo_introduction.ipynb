{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mojo for Predictive Maintenance - Introduction\n",
    "\n",
    "This notebook demonstrates **Mojo** - a new high-performance programming language from Modular that combines Python's ease of use with C/Rust-level performance.\n",
    "\n",
    "## Why Mojo for Predictive Maintenance?\n",
    "\n",
    "| Advantage | Description |\n",
    "|-----------|-------------|\n",
    "| **Performance** | Up to 35,000x faster than Python for compute-intensive tasks |\n",
    "| **Python Syntax** | Familiar syntax, easy learning curve |\n",
    "| **Edge Deployment** | Optimized for real-time inference on embedded systems |\n",
    "| **SIMD Support** | Native vectorization for signal processing |\n",
    "| **Memory Safety** | No garbage collection pauses during inference |\n",
    "\n",
    "## Use Cases in Condition Monitoring\n",
    "\n",
    "- **Real-time FFT** for vibration analysis\n",
    "- **Feature extraction** from sensor streams\n",
    "- **ML inference** with MAX Engine\n",
    "- **Edge computing** on ARM devices (Raspberry Pi, Jetson)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "```bash\n",
    "# Install Mojo (requires Linux/macOS/WSL)\n",
    "curl -fsSL https://pixi.sh/install.sh | sh\n",
    "pixi init mojo-project -c https://conda.modular.com/max-nightly/ -c conda-forge\n",
    "cd mojo-project\n",
    "pixi add mojo jupyterlab\n",
    "pixi shell\n",
    "jupyter lab\n",
    "```\n",
    "\n",
    "> **Note:** This notebook uses `%%mojo` cell magic. First run `import mojo.notebook` to enable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Mojo cell magic (run this first!)\n",
    "# If mojo is not installed, this will fail - see installation instructions above\n",
    "try:\n",
    "    import mojo.notebook\n",
    "    MOJO_AVAILABLE = True\n",
    "    print(\"Mojo notebook magic enabled! Use %%mojo in cells.\")\n",
    "except ImportError:\n",
    "    MOJO_AVAILABLE = False\n",
    "    print(\"Mojo not installed. This notebook shows code examples only.\")\n",
    "    print(\"Install with: pip install mojo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mojo Basics - Hello World\n",
    "\n",
    "Mojo looks like Python but compiles to native code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%mojo\n",
    "\n",
    "def main():\n",
    "    print(\"Hello from Mojo!\")\n",
    "    print(\"This code runs at native speed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance Comparison: Python vs Mojo\n",
    "\n",
    "Let's compare a simple computation - calculating RMS (Root Mean Square) of a signal.\n",
    "\n",
    "### Python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def rms_python(data):\n",
    "    \"\"\"Calculate RMS in pure Python (slow)\"\"\"\n",
    "    total = 0.0\n",
    "    for x in data:\n",
    "        total += x * x\n",
    "    return (total / len(data)) ** 0.5\n",
    "\n",
    "def rms_numpy(data):\n",
    "    \"\"\"Calculate RMS with NumPy (fast)\"\"\"\n",
    "    return np.sqrt(np.mean(data ** 2))\n",
    "\n",
    "# Generate test data (1 million samples)\n",
    "data = np.random.randn(1_000_000).astype(np.float64)\n",
    "\n",
    "# Benchmark pure Python\n",
    "start = time.time()\n",
    "result_py = rms_python(data)\n",
    "time_python = time.time() - start\n",
    "\n",
    "# Benchmark NumPy\n",
    "start = time.time()\n",
    "result_np = rms_numpy(data)\n",
    "time_numpy = time.time() - start\n",
    "\n",
    "print(f\"Pure Python: {time_python*1000:.2f} ms (RMS = {result_py:.6f})\")\n",
    "print(f\"NumPy:       {time_numpy*1000:.2f} ms (RMS = {result_np:.6f})\")\n",
    "print(f\"NumPy is {time_python/time_numpy:.1f}x faster than pure Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mojo Version\n",
    "\n",
    "Mojo with SIMD vectorization can be even faster than NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%mojo\n",
    "\n",
    "from math import sqrt\n",
    "from time import now\n",
    "from random import rand\n",
    "from algorithm import vectorize\n",
    "\n",
    "alias simd_width: Int = simdwidthof[DType.float64]()\n",
    "\n",
    "fn rms_mojo_scalar(data: List[Float64]) -> Float64:\n",
    "    \"\"\"Calculate RMS - scalar version (like pure Python)\"\"\"\n",
    "    var total: Float64 = 0.0\n",
    "    for i in range(len(data)):\n",
    "        total += data[i] * data[i]\n",
    "    return sqrt(total / len(data))\n",
    "\n",
    "fn rms_mojo_simd(data: DTypePointer[DType.float64], size: Int) -> Float64:\n",
    "    \"\"\"Calculate RMS - SIMD vectorized (extremely fast)\"\"\"\n",
    "    var total = SIMD[DType.float64, simd_width](0)\n",
    "    \n",
    "    @parameter\n",
    "    fn simd_sum[width: Int](i: Int):\n",
    "        let vec = data.load[width=width](i)\n",
    "        total += (vec * vec).reduce_add()\n",
    "    \n",
    "    vectorize[simd_sum, simd_width](size)\n",
    "    return sqrt(total.reduce_add() / size)\n",
    "\n",
    "def main():\n",
    "    let size = 1_000_000\n",
    "    \n",
    "    # Generate random data\n",
    "    var data = DTypePointer[DType.float64].alloc(size)\n",
    "    rand(data, size)\n",
    "    \n",
    "    # Benchmark SIMD version\n",
    "    let start = now()\n",
    "    let result = rms_mojo_simd(data, size)\n",
    "    let elapsed_ns = now() - start\n",
    "    let elapsed_ms = elapsed_ns / 1_000_000\n",
    "    \n",
    "    print(\"Mojo SIMD:  \", elapsed_ms, \"ms (RMS =\", result, \")\")\n",
    "    print(\"SIMD width:\", simd_width, \"floats processed in parallel\")\n",
    "    \n",
    "    data.free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Signal Processing: FFT in Mojo\n",
    "\n",
    "For vibration analysis, FFT is crucial. Here's a simplified DFT implementation in Mojo.\n",
    "\n",
    "> **Note:** For production, use MAX Engine with optimized FFT kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%mojo\n",
    "\n",
    "from math import sin, cos, pi\n",
    "from memory import memset_zero\n",
    "\n",
    "struct ComplexF64:\n",
    "    \"\"\"Simple complex number for FFT\"\"\"\n",
    "    var real: Float64\n",
    "    var imag: Float64\n",
    "    \n",
    "    fn __init__(inout self, real: Float64 = 0.0, imag: Float64 = 0.0):\n",
    "        self.real = real\n",
    "        self.imag = imag\n",
    "    \n",
    "    fn __add__(self, other: ComplexF64) -> ComplexF64:\n",
    "        return ComplexF64(self.real + other.real, self.imag + other.imag)\n",
    "    \n",
    "    fn __mul__(self, other: ComplexF64) -> ComplexF64:\n",
    "        return ComplexF64(\n",
    "            self.real * other.real - self.imag * other.imag,\n",
    "            self.real * other.imag + self.imag * other.real\n",
    "        )\n",
    "    \n",
    "    fn magnitude(self) -> Float64:\n",
    "        return (self.real * self.real + self.imag * self.imag) ** 0.5\n",
    "\n",
    "fn dft_magnitude(signal: List[Float64], n_freqs: Int) -> List[Float64]:\n",
    "    \"\"\"\n",
    "    Compute DFT magnitude spectrum.\n",
    "    \n",
    "    This is O(n²) - for real applications use FFT (O(n log n)).\n",
    "    \"\"\"\n",
    "    let n = len(signal)\n",
    "    var magnitudes = List[Float64]()\n",
    "    \n",
    "    for k in range(n_freqs):\n",
    "        var sum = ComplexF64(0.0, 0.0)\n",
    "        for t in range(n):\n",
    "            let angle = -2.0 * pi * k * t / n\n",
    "            let twiddle = ComplexF64(cos(angle), sin(angle))\n",
    "            sum = sum + ComplexF64(signal[t], 0.0) * twiddle\n",
    "        magnitudes.append(sum.magnitude() / n)\n",
    "    \n",
    "    return magnitudes\n",
    "\n",
    "def main():\n",
    "    # Create test signal: 10 Hz + 25 Hz components\n",
    "    let sample_rate = 100  # Hz\n",
    "    let duration = 1.0     # seconds\n",
    "    let n_samples = Int(sample_rate * duration)\n",
    "    \n",
    "    var signal = List[Float64]()\n",
    "    for i in range(n_samples):\n",
    "        let t = Float64(i) / sample_rate\n",
    "        # 10 Hz sine + 25 Hz sine\n",
    "        let value = sin(2.0 * pi * 10.0 * t) + 0.5 * sin(2.0 * pi * 25.0 * t)\n",
    "        signal.append(value)\n",
    "    \n",
    "    # Compute DFT for first 50 frequency bins\n",
    "    let magnitudes = dft_magnitude(signal, 50)\n",
    "    \n",
    "    print(\"DFT Magnitude Spectrum:\")\n",
    "    print(\"Frequency | Magnitude\")\n",
    "    print(\"-\" * 25)\n",
    "    for k in range(len(magnitudes)):\n",
    "        if magnitudes[k] > 0.1:  # Only show significant peaks\n",
    "            print(k, \"Hz     |\", magnitudes[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction for ML\n",
    "\n",
    "Extract statistical features from sensor data - optimized with Mojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%mojo\n",
    "\n",
    "from math import sqrt\n",
    "from algorithm import vectorize\n",
    "\n",
    "struct SensorFeatures:\n",
    "    \"\"\"Statistical features for ML models\"\"\"\n",
    "    var mean: Float64\n",
    "    var std: Float64\n",
    "    var rms: Float64\n",
    "    var max_val: Float64\n",
    "    var min_val: Float64\n",
    "    var peak_to_peak: Float64\n",
    "    var crest_factor: Float64\n",
    "    \n",
    "    fn __init__(inout self):\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.rms = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.peak_to_peak = 0.0\n",
    "        self.crest_factor = 0.0\n",
    "    \n",
    "    fn print_features(self):\n",
    "        print(\"Feature Extraction Results:\")\n",
    "        print(\"  Mean:          \", self.mean)\n",
    "        print(\"  Std Dev:       \", self.std)\n",
    "        print(\"  RMS:           \", self.rms)\n",
    "        print(\"  Max:           \", self.max_val)\n",
    "        print(\"  Min:           \", self.min_val)\n",
    "        print(\"  Peak-to-Peak:  \", self.peak_to_peak)\n",
    "        print(\"  Crest Factor:  \", self.crest_factor)\n",
    "\n",
    "fn extract_features(data: List[Float64]) -> SensorFeatures:\n",
    "    \"\"\"Extract statistical features from sensor data\"\"\"\n",
    "    var features = SensorFeatures()\n",
    "    let n = len(data)\n",
    "    \n",
    "    if n == 0:\n",
    "        return features\n",
    "    \n",
    "    # Single pass for mean, min, max, sum of squares\n",
    "    var sum_val: Float64 = 0.0\n",
    "    var sum_sq: Float64 = 0.0\n",
    "    features.max_val = data[0]\n",
    "    features.min_val = data[0]\n",
    "    \n",
    "    for i in range(n):\n",
    "        let val = data[i]\n",
    "        sum_val += val\n",
    "        sum_sq += val * val\n",
    "        if val > features.max_val:\n",
    "            features.max_val = val\n",
    "        if val < features.min_val:\n",
    "            features.min_val = val\n",
    "    \n",
    "    features.mean = sum_val / n\n",
    "    features.rms = sqrt(sum_sq / n)\n",
    "    features.peak_to_peak = features.max_val - features.min_val\n",
    "    \n",
    "    # Second pass for standard deviation\n",
    "    var sum_diff_sq: Float64 = 0.0\n",
    "    for i in range(n):\n",
    "        let diff = data[i] - features.mean\n",
    "        sum_diff_sq += diff * diff\n",
    "    features.std = sqrt(sum_diff_sq / n)\n",
    "    \n",
    "    # Crest factor = peak / RMS\n",
    "    if features.rms > 0:\n",
    "        let abs_max = max(abs(features.max_val), abs(features.min_val))\n",
    "        features.crest_factor = abs_max / features.rms\n",
    "    \n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Simulate vibration data with a bearing fault signature\n",
    "    var vibration_data = List[Float64]()\n",
    "    for i in range(1000):\n",
    "        let t = Float64(i) / 1000.0\n",
    "        # Normal vibration + impulse pattern (bearing fault)\n",
    "        var val = sin(2.0 * pi * 50.0 * t) * 2.0  # 50 Hz base\n",
    "        # Add impulses every 0.05 seconds (simulating bearing defect)\n",
    "        if i % 50 < 3:\n",
    "            val += 5.0  # Impulse spike\n",
    "        vibration_data.append(val)\n",
    "    \n",
    "    let features = extract_features(vibration_data)\n",
    "    features.print_features()\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    if features.crest_factor > 4.0:\n",
    "        print(\"  ⚠️  High crest factor indicates impulsive behavior\")\n",
    "        print(\"  ⚠️  Possible bearing defect detected!\")\n",
    "    else:\n",
    "        print(\"  ✓ Normal vibration pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MAX Engine: Loading ONNX Models\n",
    "\n",
    "MAX Engine can load and run ONNX models with high performance.\n",
    "\n",
    "> **Note:** This requires MAX to be installed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to demonstrate MAX Engine usage (conceptual)\n",
    "# This requires the max package to be installed\n",
    "\n",
    "MAX_EXAMPLE = '''\n",
    "from max import engine\n",
    "import numpy as np\n",
    "\n",
    "# Load an ONNX model trained for anomaly detection\n",
    "session = engine.InferenceSession()\n",
    "model = session.load(\"../models/exported/anomaly_detector.onnx\")\n",
    "\n",
    "# Prepare input data\n",
    "sensor_features = np.array([[2.5, 0.8, 3.2, 65.0, 12.4]], dtype=np.float32)\n",
    "\n",
    "# Run inference (optimized by MAX)\n",
    "outputs = model.execute(sensor_features)\n",
    "anomaly_score = outputs[0]\n",
    "\n",
    "print(f\"Anomaly Score: {anomaly_score}\")\n",
    "if anomaly_score > 0.5:\n",
    "    print(\"⚠️ Anomaly detected!\")\n",
    "else:\n",
    "    print(\"✓ Normal operation\")\n",
    "'''\n",
    "\n",
    "print(\"MAX Engine Example (requires MAX installation):\")\n",
    "print(\"=\" * 50)\n",
    "print(MAX_EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison: When to Use What?\n",
    "\n",
    "| Task | Python/NumPy | Mojo | When to choose |\n",
    "|------|--------------|------|----------------|\n",
    "| **Prototyping** | ✅ Best | ⚠️ Newer | Use Python for quick experiments |\n",
    "| **Training** | ✅ TensorFlow/PyTorch | ❌ Not yet | Python ecosystem is mature |\n",
    "| **Inference (Cloud)** | ✅ Good | ✅ Faster | Mojo/MAX for high throughput |\n",
    "| **Inference (Edge)** | ⚠️ Slow | ✅ Best | Mojo for real-time on ARM |\n",
    "| **Signal Processing** | ✅ SciPy | ✅ Faster | Mojo for custom algorithms |\n",
    "| **Custom Ops** | ⚠️ C/C++ needed | ✅ Easier | Mojo has Python-like syntax |\n",
    "\n",
    "## Recommended Workflow for Predictive Maintenance\n",
    "\n",
    "1. **Data Collection & Exploration** → Python (Pandas, Matplotlib)\n",
    "2. **Model Training** → Python (TensorFlow/PyTorch)\n",
    "3. **Export Model** → ONNX format\n",
    "4. **Inference in Production** → MAX Engine (Mojo)\n",
    "5. **Custom Signal Processing** → Mojo (for performance-critical parts)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Install Mojo: https://docs.modular.com/mojo/manual/install/\n",
    "2. Try the examples in this notebook\n",
    "3. Export your trained models to ONNX\n",
    "4. Deploy with MAX Engine for production inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Mojo Advantages for Condition Monitoring\n",
    "\n",
    "| Feature | Benefit |\n",
    "|---------|--------|\n",
    "| **SIMD Vectorization** | Fast signal processing (FFT, filtering) |\n",
    "| **No GC Pauses** | Consistent real-time performance |\n",
    "| **Python Syntax** | Easy transition from Python |\n",
    "| **ARM64 Support** | Deploy on edge devices |\n",
    "| **MAX Engine** | Optimized ONNX inference |\n",
    "\n",
    "### Current Limitations\n",
    "\n",
    "| Limitation | Workaround |\n",
    "|------------|------------|\n",
    "| No model training | Train in PyTorch, export ONNX |\n",
    "| Smaller ecosystem | Use Python for data prep |\n",
    "| Still evolving | Version 1.0 expected 2026 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
